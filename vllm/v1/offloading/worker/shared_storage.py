import aiofiles
import asyncio
import numpy as np
import math
import torch
import os
from typing import List, Optional
from pathlib import Path
from vllm.v1.offloading.worker.worker import TransferFunction, TransferSpec

from vllm.logger import init_logger

HASH_NAME_INDEX = -1  # Use the last spec's hash ID for the file name
logger = init_logger(__name__)


def get_kv_cache_base_path(
    model_name: str,
    tp_size: int,
    tp_rank: int,
    dtype: torch.dtype,
    root_dir: str = "/mnt/shared-kv",
) -> Path:
    """Return the base directory for KV cache files and ensure it exists.

    Args:
        model_name: Model identifier used to namespace files.
        tp_size: Total tensor parallel world size.
        tp_rank: Current tensor parallel rank.
        dtype: Torch dtype for the tensors saved under this path.
        root_dir: Root folder for shared storage.

    Returns:
        Path to a per-model, per-rank, per-dtype directory.
    """
    dtype_str = str(dtype).replace("torch.", "")
    base_path = Path(
        f"{root_dir}/{model_name}/tp_{tp_size}/rank_{tp_rank}/{dtype_str}"
    )
    base_path.mkdir(parents=True, exist_ok=True)
    return base_path


def get_file_name(base_path: Path, block_hash: int) -> Path:
    """Build a sharded file path for a given block hash.

    Args:
        base_path: Directory returned by get_kv_cache_base_path.
        block_hash: 64-bit integer that keys the block content.

    Returns:
        Full path to a file like base/aaaaaaaa/bbbbbbbb/aaaaaaaa bbbbbbbb.bin
        Two-level sharding keeps directories small.
    """
    block_hash_hex = f"{block_hash:x}"
    subfolder1 = block_hash_hex[:8]
    subfolder2 = block_hash_hex[8:16]
    full_path = base_path / subfolder1 / subfolder2 / f"{block_hash_hex}.bin"
    os.makedirs(full_path.parent, exist_ok=True)
    return full_path



def get_block_offset(dst_tensors: list[torch.Tensor]) -> int:
    """Get the byte offset for a given block tensor."""
    block_size_bytes = 0
    for tensor in dst_tensors:
        block = tensor[:, 0]  # Use block 0 to get the shape
        block_size_bytes += block.numel() * block.element_size()
    return block_size_bytes


# -----------------------
# Synchronous helpers
# -----------------------

def convert_tensors_to_bytes(
    src_tensors: List[torch.Tensor],
    block_ids_list: List[int],
) -> memoryview:
    """Serialize selected [K, V] blocks from all layers to bytes.

    Args:
        src_tensors: List of per-layer tensors with shape
            [2, num_blocks, num_heads, block_size, head_size].
        block_ids_list: Block indices to extract in order.

    Returns:
        A memoryview over a NumPy buffer backed by CPU memory.
        Order is by block id outer loop, then by layer.
    """
    blocks = []
    for block_id in block_ids_list:
        for tensor in src_tensors:
            # Select the full [K, V] slice for this block across heads
            block = tensor[:, block_id]
            blocks.append(block)
    # Flatten across layers and K/V
    flat = torch.cat(blocks, dim=0)
    flat = flat.contiguous().detach().cpu()
    return memoryview(flat.numpy())


def write_buffer_to_file(target_file: Path, buffer: memoryview) -> None:
    """Atomically write a buffer to target_file on POSIX systems.

    Args:
        target_file: Destination path to write.
        buffer: Bytes-like memoryview to persist.

    Notes:
        Writes to a .tmp file then renames to avoid partial files on crash.
    """
    tmp_file_path = target_file.with_suffix(".tmp")
    with open(tmp_file_path, "wb") as f:
        f.write(buffer)
        f.flush()
        os.fsync(f.fileno())
    os.replace(tmp_file_path, target_file)



def convert_bytes_to_tensors(
    buffer: bytes,
    dst_tensors: List[torch.Tensor],
    gpu_blocks_per_file: int,
    block_ids_list: List[int],
    block_offset: int
) -> None:
    """Restore bytes into the given destination tensors by block id."""

    mv = memoryview(buffer)  # zero-copy view over the whole file
    offset = 0
    assert len(block_ids_list) <= gpu_blocks_per_file # length should be smaller
    if len(block_ids_list) % gpu_blocks_per_file != 0:
        offset = block_offset *(gpu_blocks_per_file - len(block_ids_list)) # If not full blocks, start at the offset

    for block_id in block_ids_list:
        for tensor in dst_tensors:

            block = tensor[:, block_id]
            num_bytes = block.numel() * block.element_size()
            # slice the memoryview without copying
            mv_block = mv[offset:offset + num_bytes]
            offset += num_bytes

            # interpret bytes as numpy with the matching dtype
            np_dtype = torch_dtype_to_numpy(block.dtype)
            np_arr = np.frombuffer(mv_block, dtype=np_dtype).reshape(block.shape)

            # make a torch tensor from the numpy view (CPU)
            src = torch.from_numpy(np_arr)

            # handle bf16 if you store it as uint16 on disk
            if block.dtype is torch.bfloat16 and src.dtype != torch.bfloat16:
                src = src.view(torch.bfloat16)

            # move to the right dtype and device, then copy into place
            if src.dtype != block.dtype or src.device != block.device:
                src = src.to(device=block.device, dtype=block.dtype, non_blocking=True)

            block.copy_(src)


def torch_dtype_to_numpy(dtype) -> np.dtype:
    mapping = {
        torch.float16: np.float16,
        torch.float32: np.float32,
        torch.int8:    np.int8,
        torch.int16:   np.int16,
        torch.int32:   np.int32,
        torch.int64:   np.int64,
        # If you support bf16, store as uint16 on disk, then view to bfloat16 after
        torch.bfloat16: np.uint16,
    }
    return mapping[dtype]

# ----------------------------------------
# Async wrappers and loop runner
# ----------------------------------------

def _run_async_in_thread(coro) -> bool:
    """Run an async coroutine in a new event loop inside a background thread.

    Args:
        coro: Awaitable object to run to completion.

    Returns:
        True on success. False only if inner code returns False.

    Raises:
        Propagates any exception raised inside the coroutine.
    """
    from threading import Thread

    result = {"ok": False, "exc": None}

    def _runner():
        loop = asyncio.new_event_loop()  #Create a brand-new asyncio event loop for this background thread
        try:
            asyncio.set_event_loop(loop)  # Set the new loop as the current event loop for this thread
            result["ok"] = loop.run_until_complete(coro)
        except Exception as e:
            result["exc"] = e
        finally:
            try:
                loop.close()
            except Exception:
                pass

    t = Thread(target=_runner, daemon=True) # Create a background daemon thread that runs _runner()
    t.start() # Start the thread â€” the coroutine begins executing in the new event loop
    t.join() # Wait until the background thread finishes

    if result["exc"]:
        raise result["exc"]

    return result["ok"]


async def _to_bytes_async(src_tensors: List[torch.Tensor], block_ids: List[int]) -> memoryview:
    """Serialize tensors off the event loop using a thread pool.

    Args:
        src_tensors: Source tensors to serialize.
        block_ids: Block ids to extract.

    Returns:
        Memoryview with serialized bytes.
    """
    loop = asyncio.get_running_loop()  # Get the currently running asyncio event loop for this task
    return await loop.run_in_executor( # Schedule a blocking CPU-bound function to run in a background thread
        None, lambda: convert_tensors_to_bytes(src_tensors, block_ids)
    )


async def _from_bytes_async(
    buffer: bytes, dst_tensors: List[torch.Tensor], gpu_blocks_per_file: int, block_ids: List[int], block_offset: int
) -> None:
    """Deserialize bytes into destination tensors off the event loop.

    Args:
        buffer: Bytes returned by file read.
        dst_tensors: Destination tensors to write.
        block_ids: Block ids to fill.
    """
    loop = asyncio.get_running_loop()  # Get the currently running asyncio event loop for this task
    return await loop.run_in_executor( # Schedule a blocking CPU-bound function to run in a background thread
        None, lambda: convert_bytes_to_tensors(buffer, dst_tensors, gpu_blocks_per_file, block_ids, block_offset )
    )


async def _write_file_async(target: Path, buf: memoryview) -> None:
    """Write buf to target atomically using aiofiles - short and clear."""
    tmp = target.with_suffix(".tmp")
    async with aiofiles.open(tmp, "wb") as f:
        await f.write(buf)
    os.replace(tmp, target)

async def _read_file_async(path: Path) -> bytes:
    """Read a file using aiofiles to allow concurrency.

    Args:
        path: File path to read.

    Returns:
        File content as bytes.
    """
    async with aiofiles.open(path, "rb") as f:
        return await f.read()


# -----------------------------
# Flexible PUT (supports grouping)
# -----------------------------

def generate_put_transfer_function(
    model_name: str,
    tp_size: int,
    tp_rank: int,
    src_tensors: List[torch.Tensor],
    gpu_blocks_per_file: int,  # number of GPU blocks per file
    dtype: torch.dtype,
    root_dir: str,
    max_concurrency: int,
) -> TransferFunction:
    """Create a TransferFunction that writes blocks to shared storage.

    Args:
        model_name: Model identifier for path namespacing.
        tp_size: Tensor parallel world size.
        tp_rank: Current tensor parallel rank.
        src_tensors: Per-layer KV tensors to pull blocks from.
        gpu_blocks_per_file: Number of source blocks to group into one file.
        dtype: Data type used to choose the directory.
        root_dir: Root folder for shared storage.
        max_concurrency: Max concurrent file tasks.

    Returns:
        A callable that matches TransferFunction(spec) -> bool.
    """
    base_path = get_kv_cache_base_path(
        model_name=model_name,
        tp_size=tp_size,
        tp_rank=tp_rank,
        dtype=dtype,
        root_dir=root_dir,
    )

    async def _write_group(dst_spec, block_ids: List[int], sem: asyncio.Semaphore) -> bool:
        """Write one grouped file for a destination spec.

        Args:
            dst_spec: Storage spec that holds the block_hash.
            block_ids: Source block ids to group into this file.
            sem: Concurrency limiter.
        """
        block_hash = dst_spec.block_hash
        target_file = get_file_name(base_path, block_hash)

        # Idempotent: if file exists, skip work and return success.
        if os.path.exists(target_file):
            return True

        async with sem:
            try:
                buf = await _to_bytes_async(src_tensors, block_ids)
                await _write_file_async(target_file, buf)
                return True
            except Exception as e:
                logger.warning("PUT failed for %s: %r", target_file, e)
                # Best effort cleanup of partial file.
                try:
                    if os.path.exists(target_file):
                        os.remove(target_file)
                except Exception:
                    pass
                return False

    async def _main_put(src_specs, dst_specs) -> bool:
        """Plan and execute grouped writes in parallel.

        Args:
            src_specs: List of GPU specs with .block_id fields.
            dst_specs: List of storage specs with .block_hash fields.
        """
        sem = asyncio.Semaphore(max_concurrency)
        tasks = []

        # Pack gpu_blocks_per_file source specs into each destination spec.
        for i, dst_spec in enumerate(dst_specs):
            start = i * gpu_blocks_per_file
            end = min((i + 1) * gpu_blocks_per_file, len(src_specs))
            if start >= len(src_specs):
                break
            block_ids = [src_specs[j].block_id for j in range(start, end)]
            tasks.append(_write_group(dst_spec, block_ids, sem))

        if not tasks:
            return True

        results = await asyncio.gather(*tasks, return_exceptions=True)
        return all(r is True for r in results)

    def transfer_function(spec: TransferSpec) -> bool:
        """Entry point used by the worker to perform PUT.

        Args:
            spec: Tuple of (src_specs, dst_specs).

        Returns:
            True if all grouped writes succeeded.
        """
        src_specs, dst_specs = spec
        try:
            return _run_async_in_thread(_main_put(src_specs, dst_specs))
        except Exception as e:
            logger.warning("PUT transfer failed: %r", e)
            return False

    return transfer_function


# -----------------------------
# Flexible GET (supports grouping)
# -----------------------------

def generate_get_transfer_function(
    dst_tensors: List[torch.Tensor],
    gpu_blocks_per_file: int,  # number of destination blocks per file
    model_name: str,
    tp_size: int,
    tp_rank: int,
    dtype: torch.dtype,
    root_dir: str,
    max_concurrency: int,
) -> TransferFunction:
    """Create a TransferFunction that reads blocks from shared storage.

    Args:
        dst_tensors: Per-layer KV tensors to write restored blocks into.
        gpu_blocks_per_file: Number of destination blocks each file provides.
        model_name: Model identifier for path namespacing.
        tp_size: Tensor parallel world size.
        tp_rank: Current tensor parallel rank.
        dtype: Data type used to choose the directory.
        root_dir: Root folder for shared storage.
        max_concurrency: Max concurrent file tasks.

    Returns:
        A callable that matches TransferFunction(spec) -> bool.
    """
    base_path = get_kv_cache_base_path(
        model_name=model_name,
        tp_size=tp_size,
        tp_rank=tp_rank,
        dtype=dtype,
        root_dir=root_dir,
    )

    block_offset = get_block_offset(dst_tensors)
    async def _read_group(src_spec, block_ids: List[int], sem: asyncio.Semaphore) -> bool:
        """Read one grouped file and fill the destination blocks.

        Args:
            src_spec: Storage spec that holds the block_hash.
            block_ids: Destination block ids to fill from this file.
            sem: Concurrency limiter.
        """
        block_hash = src_spec.block_hash
        path = get_file_name(base_path, block_hash)

        async with sem:
            try:
                buf = await _read_file_async(path)
            except Exception as e:
                logger.warning("GET read failed for %s: %r", path, e)
                return False

            try:
                await _from_bytes_async(buf, dst_tensors, gpu_blocks_per_file, block_ids, block_offset)
                return True
            except Exception as e:
                logger.warning("GET convert failed for %s: %r", path, e)
                return False

    async def _main_get(src_specs, dst_specs) -> bool:
        """Plan and execute grouped reads in parallel.

        Args:
            src_specs: List of storage specs with .block_hash fields.
            dst_specs: List of GPU specs with .block_id fields.
        """
        sem = asyncio.Semaphore(max_concurrency)
        tasks = []

        # The first group may be partial, so calculate its length
        first_len = len(dst_specs) % gpu_blocks_per_file or gpu_blocks_per_file
        start = 0

        # Each src_spec file restores gpu_blocks_per_file destination blocks.
        for i, src_spec in enumerate(src_specs):
            if start >= len(dst_specs):
                break

            size = first_len if i == 0 else gpu_blocks_per_file
            end = min(start + size, len(dst_specs))
            block_ids = [dst_specs[j].block_id for j in range(start, end)]
            tasks.append(_read_group(src_spec, block_ids, sem))

            start += size

        if not tasks:
            return True

        results = await asyncio.gather(*tasks, return_exceptions=True)
        return all(r is True for r in results)

    def transfer_function(spec: TransferSpec) -> bool:
        """Entry point used by the worker to perform GET.

        Args:
            spec: Tuple of (src_specs, dst_specs).

        Returns:
            True if all grouped reads and conversions succeeded.
        """
        src_specs, dst_specs = spec
        assert len(src_specs) == math.ceil(len(dst_specs) / gpu_blocks_per_file), \
            f"Mismatch sizes of source spec {len(src_specs)} and destination specs {len(dst_specs)}, gpu_blocks_per_file {gpu_blocks_per_file}"
        try:
            return _run_async_in_thread(_main_get(src_specs, dst_specs))
        except Exception as e:
            logger.warning("GET transfer failed: %r", e)
            return False

    return transfer_function
